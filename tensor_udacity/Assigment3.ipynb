{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_rel_path = '../datasets/notmnist/notMNIST.pickle'\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle location: C:\\Users\\lgess\\Documents\\repo\\learning_ai\\datasets\\notmnist\\notMNIST.pickle\n",
      "dict_keys(['test_dataset', 'train_labels', 'test_labels', 'valid_dataset', 'train_dataset', 'valid_labels'])\n"
     ]
    }
   ],
   "source": [
    "# Discover pickle path\n",
    "file_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "pickle_path = os.path.abspath(os.path.join(file_dir, pickle_rel_path))\n",
    "print('Pickle location:',pickle_path)\n",
    "\n",
    "# Load pickle\n",
    "with open(pickle_path,'rb') as file:\n",
    "    datasets = pickle.load(file)\n",
    "print(datasets.keys())\n",
    "\n",
    "# Set variables\n",
    "train_dataset = datasets['train_dataset']\n",
    "orig_train_labels = datasets['train_labels'] \n",
    "validate_dataset = datasets['valid_dataset']\n",
    "orig_validate_labels = datasets['valid_labels'] \n",
    "test_dataset = datasets['test_dataset']\n",
    "orig_test_labels = datasets['test_labels'] \n",
    "\n",
    "# Convert labels representation\n",
    "num_labels = 10\n",
    "def setup_labels(label_array, num_labels):\n",
    "    return ((np.arange(num_labels) == label_array[:,None]).astype(np.float32))\n",
    "train_labels = setup_labels(orig_train_labels, num_labels)\n",
    "validate_labels = setup_labels(orig_validate_labels, num_labels)\n",
    "test_labels = setup_labels(orig_test_labels, num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, w_shape, b_shape, name=\"\"):\n",
    "        self.name = name    \n",
    "        self.w_shape = w_shape\n",
    "        self.b_shape = b_shape\n",
    "        \n",
    "    def create_vars(self):\n",
    "        with tf.name_scope(self.name):\n",
    "            initializer = tf.glorot_normal_initializer()\n",
    "            self.w = tf.get_variable(name=\"W\"+self.name, shape=self.w_shape, dtype=tf.float32, initializer=initializer)\n",
    "            self.b = tf.get_variable(name=\"B\"+self.name, shape=self.b_shape, dtype=tf.float32, initializer=initializer)  \n",
    "    \n",
    "    def weighted_inputs(self, x): \n",
    "        with tf.name_scope(self.name):\n",
    "            return tf.matmul(x, tf.transpose(self.w))+self.b\n",
    "    \n",
    "    def inference(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def training(self, x, y):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class HiddenLayer(Layer):       \n",
    "        \n",
    "    def inference(self, x):\n",
    "        with tf.name_scope(self.name):\n",
    "             return tf.nn.relu(self.weighted_inputs(x))\n",
    "            \n",
    "    def training(self, x, y, keep_prob):\n",
    "        with tf.name_scope(self.name):\n",
    "            x = tf.cond(keep_prob<1, lambda: tf.nn.dropout(x, keep_prob), lambda: x)\n",
    "            return self.inference(x)\n",
    "                          \n",
    "class OutputLayer(Layer):\n",
    "        \n",
    "    def inference(self, x):\n",
    "        with tf.name_scope(self.name):\n",
    "            logits = self.weighted_inputs(x)\n",
    "            return tf.nn.softmax(logits)\n",
    "                             \n",
    "    def training(self, x, y, keep_prob):\n",
    "        with tf.name_scope(self.name):\n",
    "            #x = tf.nn.dropout(x, keep_prob)\n",
    "            logits = self.weighted_inputs(x)\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "            loss = tf.reduce_mean(cross_entropy)\n",
    "            return loss\n",
    "        \n",
    "class Model:\n",
    "                          \n",
    "    def __init__(self, layers, name=\"\"):\n",
    "        self.name = name\n",
    "        self.layers = layers   \n",
    "        \n",
    "    def create_vars(self):\n",
    "        for layer in self.layers:\n",
    "            layer.create_vars()\n",
    "                          \n",
    "    def inference(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.inference(x)\n",
    "        return x\n",
    "                          \n",
    "    def loss(self, x, y, keep_prob, regularization):\n",
    "        l2 = 0\n",
    "        for layer in self.layers:\n",
    "            x = layer.training(x, y, keep_prob)\n",
    "            l2_reg = l2 + tf.nn.l2_loss(layer.w)/tf.cast(tf.size(layer.w),tf.float32)\n",
    "            l2 = tf.cond(regularization > 0, lambda: l2_reg, lambda: 0.0)\n",
    "        return x + regularization*l2\n",
    "    \n",
    "def create_simple_classifier(features_shape, num_neurons_array, num_labels):\n",
    "                            \n",
    "    layers = []    \n",
    "    w_shape = None\n",
    "    b_shape = features_shape\n",
    "    index = 1\n",
    "\n",
    "    for num_neurons in num_neurons_array:\n",
    "        w_shape = np.append([num_neurons],b_shape)\n",
    "        b_shape = [num_neurons]\n",
    "        layers.append(HiddenLayer(w_shape, b_shape, name=\"Layer\"+str(index)))\n",
    "        index+=1\n",
    "\n",
    "    w_shape = np.append([num_labels],b_shape)\n",
    "    b_shape = [num_labels]\n",
    "    layers.append(OutputLayer(w_shape, b_shape, name=\"Layer\"+str(index))) \n",
    "\n",
    "    return Model(layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionRunner:\n",
    "    \n",
    "    def __init__(self, features_shape, num_neurons_array, num_labels):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.session = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "            self.x = tf.placeholder(dtype=tf.float32,shape=np.append(None,features_shape), name=\"x\")\n",
    "            self.y = tf.placeholder(dtype=tf.float32,shape=np.append(None,[num_labels]), name=\"y\")\n",
    "            self.keep_prob = tf.placeholder(dtype=tf.float32,shape=[], name=\"keep_prob\")\n",
    "            self.regularization = tf.placeholder(dtype=tf.float32,shape=[], name=\"regularization\")\n",
    "            model = create_simple_classifier(features_shape, num_neurons_array, num_labels)\n",
    "            model.create_vars()\n",
    "            self.inference = model.inference(self.x)\n",
    "            self.loss = model.loss(self.x,self.y,self.keep_prob,self.regularization)\n",
    "\n",
    "    def train(self, train_dataset, train_labels, \n",
    "              batch_size=200, learning_rate=0.5, iterations=1000, keep_prob=0.75, regularization=0):\n",
    "        \n",
    "        index = 0\n",
    "        num_data = len(train_dataset)\n",
    "        if batch_size > num_data:\n",
    "            batch_size = num_data\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            init = tf.global_variables_initializer()\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "            step = optimizer.minimize(self.loss, name=\"Optimizer\")  \n",
    "        \n",
    "        self.session.run(init)\n",
    "        \n",
    "        for i in range(iterations):   \n",
    "            if 2*batch_size < num_data:\n",
    "                index = (i*batch_size)%(len(train_dataset)-batch_size)\n",
    "            feed_dict={self.x: train_dataset[index:index+batch_size], \n",
    "                       self.y: train_labels[index:index+batch_size],\n",
    "                       self.keep_prob: keep_prob,\n",
    "                       self.regularization: regularization}      \n",
    "            self.session.run(step, feed_dict)\n",
    "            if i%(iterations/10) == 0:\n",
    "                loss_value = self.session.run(self.loss, feed_dict)\n",
    "                print(loss_value)\n",
    "                \n",
    "    def predict(self, dataset):\n",
    "        return self.session.run(self.inference, feed_dict={self.x: dataset})\n",
    "        \n",
    "    def evaluate(self, dataset, labels):\n",
    "        print(self.__accuracy(predicted=self.predict(dataset), expected=labels))\n",
    "        \n",
    "    def __accuracy(self, predicted, expected):\n",
    "        return np.mean(np.argmax(predicted,1) == np.argmax(expected,1))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2356555\n",
      "0.23251127\n",
      "0.2479821\n",
      "0.14364482\n",
      "0.12980384\n",
      "0.117294915\n",
      "0.11538116\n",
      "0.0962862\n",
      "0.08884112\n",
      "0.08469728\n"
     ]
    }
   ],
   "source": [
    "features_shape = train_dataset.shape[1:]\n",
    "num_features = features_shape[0]*features_shape[1]\n",
    "\n",
    "try:\n",
    "    session_runner.session.close()\n",
    "except:\n",
    "    None\n",
    "session_runner = SessionRunner(features_shape=[num_features], \n",
    "                               num_neurons_array = [100,100,100,100],\n",
    "                               num_labels = (10))\n",
    "num_samples = 200\n",
    "session_runner.train(train_dataset.reshape([-1,num_features])[0:num_samples], train_labels[0:num_samples], \n",
    "                     batch_size=10, learning_rate=0.2, iterations=5000, keep_prob=0.9, regularization=10) #batch=1000\n",
    "writer = tf.summary.FileWriter(\"/tf.log\", session_runner.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n",
      "0.7438\n",
      "0.8153\n"
     ]
    }
   ],
   "source": [
    "session_runner.evaluate(train_dataset.reshape([-1,num_features])[0:num_samples], train_labels[0:num_samples])\n",
    "session_runner.evaluate(validate_dataset.reshape([-1,num_features]), validate_labels)\n",
    "session_runner.evaluate(test_dataset.reshape([-1,num_features]), test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2049df98a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_sample(sample_image, label):\n",
    "    plt.figure()\n",
    "    plt.imshow(sample_image)\n",
    "    print('Label:', np.argmax(label))\n",
    "\n",
    "index=0\n",
    "show_sample(validate_dataset[index],validate_labels[index])\n",
    "np.argmax(session_runner.predict([validate_dataset[index].reshape([num_features])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
